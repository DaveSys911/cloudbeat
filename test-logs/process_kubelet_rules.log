============================= test session starts ==============================
platform linux -- Python 3.9.13, pytest-7.1.2, pluggy-1.0.0 -- /usr/local/bin/python
cachedir: .pytest_cache
rootdir: /usr/src/app, configfile: pyproject.toml
plugins: xdist-2.5.0, order-1.0.1, forked-1.4.0, allure-pytest-2.9.45, dependency-0.5.1
/usr/src/app/product/tests/test_kube_api_rules.py:13: PytestUnknownMarkWarning: Unknown pytest.mark.k8s_object_rules - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
  @pytest.mark.k8s_object_rules
/usr/src/app/product/tests/test_process_api_server_rules.py:14: PytestUnknownMarkWarning: Unknown pytest.mark.process_api_server_rules - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
  @pytest.mark.process_api_server_rules
/usr/src/app/product/tests/test_process_controller_manager_rules.py:14: PytestUnknownMarkWarning: Unknown pytest.mark.process_controller_manager_rules - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
  @pytest.mark.process_controller_manager_rules
/usr/src/app/product/tests/test_process_etcd_rules.py:14: PytestUnknownMarkWarning: Unknown pytest.mark.process_etcd_rules - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
  @pytest.mark.process_etcd_rules
/usr/src/app/product/tests/test_process_kubelet_rules.py:14: PytestUnknownMarkWarning: Unknown pytest.mark.process_kubelet_rules - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
  @pytest.mark.process_kubelet_rules
/usr/src/app/product/tests/test_process_scheduler_rules.py:14: PytestUnknownMarkWarning: Unknown pytest.mark.process_scheduler_rules - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
  @pytest.mark.process_scheduler_rules
/usr/src/app/product/tests/test_rules.py:13: PytestUnknownMarkWarning: Unknown pytest.mark.file_system_rules - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
  @pytest.mark.file_system_rules
collecting ... collected 186 items / 163 deselected / 23 selected

product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.1-dictionary0-/var/lib/kubelet/config.yaml-failed] service_account created.
lease created.
role created.
role created.
cluster_role created.
role_binding created.
role_binding created.
cluster_role_binding created.
config_map created.
daemon_set created. status='{'collision_count': None,
 'conditions': None,
 'current_number_scheduled': 0,
 'desired_number_scheduled': 0,
 'number_available': None,
 'number_misscheduled': 0,
 'number_ready': 0,
 'number_unavailable': None,
 'observed_generation': None,
 'updated_number_scheduled': None}'
FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.1-dictionary1-/var/lib/kubelet/config.yaml-passed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.2-dictionary2-/var/lib/kubelet/config.yaml-failed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.2-dictionary3-/var/lib/kubelet/config.yaml-passed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.3-dictionary4-/var/lib/kubelet/config.yaml-failed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.4-dictionary5-/var/lib/kubelet/config.yaml-failed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.4-dictionary6-/var/lib/kubelet/config.yaml-passed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.5-dictionary7-/var/lib/kubelet/config.yaml-failed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.5-dictionary8-/var/lib/kubelet/config.yaml-passed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.6-dictionary9-/var/lib/kubelet/config.yaml-failed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.6-dictionary10-/var/lib/kubelet/config.yaml-passed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.7-dictionary11-/var/lib/kubelet/config.yaml-failed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.7-dictionary12-/var/lib/kubelet/config.yaml-passed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.9-dictionary13-/var/lib/kubelet/config.yaml-failed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.9-dictionary14-/var/lib/kubelet/config.yaml-passed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.10-dictionary15-/var/lib/kubelet/config.yaml-passed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.11-dictionary16-/var/lib/kubelet/config.yaml-failed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.11-dictionary17-/var/lib/kubelet/config.yaml-passed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.12-dictionary18-/var/lib/kubelet/config.yaml-passed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.12-dictionary19-/var/lib/kubelet/config.yaml-passed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.13-dictionary20-/var/lib/kubelet/config.yaml-failed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.13-dictionary21-/var/lib/kubelet/config.yaml-passed] FAILED
product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.13-dictionary22-/var/lib/kubelet/config.yaml-passed] FAILED

=================================== FAILURES ===================================
_ test_process_kubelet[CIS 4.2.1-dictionary0-/var/lib/kubelet/config.yaml-failed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.1'
dictionary = {'set': {'authentication': {'anonymous': {'enabled': True}}}}
resource = '/var/lib/kubelet/config.yaml', expected = 'failed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.1 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.1-dictionary1-/var/lib/kubelet/config.yaml-passed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.1'
dictionary = {'set': {'authentication': {'anonymous': {'enabled': False}}}}
resource = '/var/lib/kubelet/config.yaml', expected = 'passed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.1 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.2-dictionary2-/var/lib/kubelet/config.yaml-failed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.2'
dictionary = {'set': {'authorization': {'mode': 'AlwaysAllow'}}}
resource = '/var/lib/kubelet/config.yaml', expected = 'failed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.2 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.2-dictionary3-/var/lib/kubelet/config.yaml-passed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.2'
dictionary = {'set': {'authorization': {'mode': 'Webhook'}}}
resource = '/var/lib/kubelet/config.yaml', expected = 'passed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.2 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.3-dictionary4-/var/lib/kubelet/config.yaml-failed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.3'
dictionary = {'unset': ['authentication.x509.clientCAFile']}
resource = '/var/lib/kubelet/config.yaml', expected = 'failed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.3 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.4-dictionary5-/var/lib/kubelet/config.yaml-failed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.4', dictionary = {'set': {'readOnlyPort': 26492}}
resource = '/var/lib/kubelet/config.yaml', expected = 'failed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.4 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.4-dictionary6-/var/lib/kubelet/config.yaml-passed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.4', dictionary = {'set': {'readOnlyPort': 0}}
resource = '/var/lib/kubelet/config.yaml', expected = 'passed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.4 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.5-dictionary7-/var/lib/kubelet/config.yaml-failed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.5'
dictionary = {'set': {'streamingConnectionIdleTimeout': 0}}
resource = '/var/lib/kubelet/config.yaml', expected = 'failed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.5 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.5-dictionary8-/var/lib/kubelet/config.yaml-passed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.5'
dictionary = {'set': {'streamingConnectionIdleTimeout': '26492s'}}
resource = '/var/lib/kubelet/config.yaml', expected = 'passed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.5 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.6-dictionary9-/var/lib/kubelet/config.yaml-failed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.6', dictionary = {'set': {'protectKernelDefaults': False}}
resource = '/var/lib/kubelet/config.yaml', expected = 'failed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.6 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.6-dictionary10-/var/lib/kubelet/config.yaml-passed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.6', dictionary = {'set': {'protectKernelDefaults': True}}
resource = '/var/lib/kubelet/config.yaml', expected = 'passed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.6 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.7-dictionary11-/var/lib/kubelet/config.yaml-failed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.7', dictionary = {'set': {'makeIPTablesUtilChains': False}}
resource = '/var/lib/kubelet/config.yaml', expected = 'failed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.7 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.7-dictionary12-/var/lib/kubelet/config.yaml-passed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.7', dictionary = {'set': {'makeIPTablesUtilChains': True}}
resource = '/var/lib/kubelet/config.yaml', expected = 'passed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.7 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.9-dictionary13-/var/lib/kubelet/config.yaml-failed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.9', dictionary = {'set': {'eventRecordQPS': 4}}
resource = '/var/lib/kubelet/config.yaml', expected = 'failed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.9 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.9-dictionary14-/var/lib/kubelet/config.yaml-passed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.9', dictionary = {'set': {'eventRecordQPS': 0}}
resource = '/var/lib/kubelet/config.yaml', expected = 'passed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.9 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.10-dictionary15-/var/lib/kubelet/config.yaml-passed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.10'
dictionary = {'set': {'tlsCertFile': '', 'tlsPrivateKeyFile': ''}}
resource = '/var/lib/kubelet/config.yaml', expected = 'passed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.10 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.11-dictionary16-/var/lib/kubelet/config.yaml-failed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.11', dictionary = {'set': {'rotateCertificates': False}}
resource = '/var/lib/kubelet/config.yaml', expected = 'failed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.11 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.11-dictionary17-/var/lib/kubelet/config.yaml-passed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.11', dictionary = {'set': {'rotateCertificates': True}}
resource = '/var/lib/kubelet/config.yaml', expected = 'passed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.11 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.12-dictionary18-/var/lib/kubelet/config.yaml-passed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.12'
dictionary = {'set': {'featureGates': {'RotateKubeletServerCertificate': True}, 'serverTLSBootstrap': False}}
resource = '/var/lib/kubelet/config.yaml', expected = 'passed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.12 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.12-dictionary19-/var/lib/kubelet/config.yaml-passed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.12'
dictionary = {'set': {'featureGates': {'RotateKubeletServerCertificate': False}, 'serverTLSBootstrap': True}}
resource = '/var/lib/kubelet/config.yaml', expected = 'passed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.12 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.13-dictionary20-/var/lib/kubelet/config.yaml-failed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.13'
dictionary = {'set': {'TLSCipherSuites': ['TLS_ECDHE_ECDSA_WITH_AES_128_GCM_DUMMY']}}
resource = '/var/lib/kubelet/config.yaml', expected = 'failed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.13 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.13-dictionary21-/var/lib/kubelet/config.yaml-passed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.13'
dictionary = {'set': {'TLSCipherSuites': ['TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256']}}
resource = '/var/lib/kubelet/config.yaml', expected = 'passed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.13 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
_ test_process_kubelet[CIS 4.2.13-dictionary22-/var/lib/kubelet/config.yaml-passed] _

config_node_pre_test = (<commonlib.kubernetes.KubernetesHelper object at 0xffffa8497340>, <class 'commonlib.io_utils.FsClient'>, Munch({'name': 'cloudbeat', 'namespace': 'kube-system', 'findings_timeout': 30}))
rule_tag = 'CIS 4.2.13'
dictionary = {'set': {'TLSCipherSuites': ['TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256', 'TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256', 'TLS_...RSA_WITH_AES_256_GCM_SHA384', 'TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305', 'TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384', ...]}}
resource = '/var/lib/kubelet/config.yaml', expected = 'passed'

    @pytest.mark.process_kubelet_rules
    @pytest.mark.parametrize(
        ("rule_tag", "dictionary", "resource", "expected"),
        kubelet_rules,
    )
    def test_process_kubelet(config_node_pre_test,
                             rule_tag,
                             dictionary,
                             resource,
                             expected):
        """
        This data driven test verifies rules and findings return by cloudbeat agent.
        In order to add new cases @pytest.mark.parameterize section shall be updated.
        Setup and teardown actions are defined in data method.
        This test creates cloudbeat agent instance, changes node resources (modes, users, groups) and verifies,
        that cloudbeat returns correct finding.
        @param rule_tag: Name of rule to be verified.
        @param dictionary: Set and Unset dictionary
        @param resource: Full path to resource / file
        @param expected: Result to be found in finding evaluation field.
        @return: None - Test Pass / Fail result is generated.
        """
        k8s_client, api_client, cloudbeat_agent = config_node_pre_test
    
        if not "edit_config_file" in dir(api_client):
            pytest.skip("skipping process rules run in non-containerized api_client")
    
        # Currently, single node is used, in the future may be extended for all nodes.
        node = k8s_client.get_cluster_nodes()[0]
        pods = k8s_client.get_agent_pod_instances(agent_name=cloudbeat_agent.name, namespace=cloudbeat_agent.namespace)
    
        api_client.edit_config_file(container_name=node.metadata.name,
                                dictionary=dictionary,
                                resource=resource)
    
        # Wait for updated file fetch
        # TODO: Implement a more optimal way of waiting
        time.sleep(60)
    
        evaluation = get_evaluation(
            k8s=k8s_client,
            timeout=cloudbeat_agent.findings_timeout,
            pod_name=pods[0].metadata.name,
            namespace=cloudbeat_agent.namespace,
            rule_tag=rule_tag,
            exec_timestamp=datetime.utcnow(),
        )
    
>       assert evaluation is not None, f"No evaluation for rule {rule_tag} could be found"
E       AssertionError: No evaluation for rule CIS 4.2.13 could be found
E       assert None is not None

product/tests/test_process_kubelet_rules.py:62: AssertionError
=========================== short test summary info ============================
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.1-dictionary0-/var/lib/kubelet/config.yaml-failed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.1-dictionary1-/var/lib/kubelet/config.yaml-passed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.2-dictionary2-/var/lib/kubelet/config.yaml-failed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.2-dictionary3-/var/lib/kubelet/config.yaml-passed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.3-dictionary4-/var/lib/kubelet/config.yaml-failed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.4-dictionary5-/var/lib/kubelet/config.yaml-failed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.4-dictionary6-/var/lib/kubelet/config.yaml-passed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.5-dictionary7-/var/lib/kubelet/config.yaml-failed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.5-dictionary8-/var/lib/kubelet/config.yaml-passed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.6-dictionary9-/var/lib/kubelet/config.yaml-failed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.6-dictionary10-/var/lib/kubelet/config.yaml-passed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.7-dictionary11-/var/lib/kubelet/config.yaml-failed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.7-dictionary12-/var/lib/kubelet/config.yaml-passed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.9-dictionary13-/var/lib/kubelet/config.yaml-failed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.9-dictionary14-/var/lib/kubelet/config.yaml-passed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.10-dictionary15-/var/lib/kubelet/config.yaml-passed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.11-dictionary16-/var/lib/kubelet/config.yaml-failed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.11-dictionary17-/var/lib/kubelet/config.yaml-passed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.12-dictionary18-/var/lib/kubelet/config.yaml-passed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.12-dictionary19-/var/lib/kubelet/config.yaml-passed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.13-dictionary20-/var/lib/kubelet/config.yaml-failed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.13-dictionary21-/var/lib/kubelet/config.yaml-passed]
FAILED product/tests/test_process_kubelet_rules.py::test_process_kubelet[CIS 4.2.13-dictionary22-/var/lib/kubelet/config.yaml-passed]
=============== 23 failed, 163 deselected in 2078.90s (0:34:38) ================
